# üç∑ Desafio de An√°lise e Predi√ß√£o de Qualidade de Vinhos

## üìã Descri√ß√£o do Desafio

Bem-vindo ao **Desafio de An√°lise e Predi√ß√£o de Qualidade de Vinhos**! Este √© um desafio completo de Machine Learning e Data Science que aborda m√∫ltiplos aspectos da an√°lise de dados, desde a explora√ß√£o at√© a modelagem preditiva e imputa√ß√£o de valores faltantes.

---

## üéØ Objetivos do Desafio

Este desafio √© dividido em **5 etapas principais**, cada uma com seus pr√≥prios objetivos e complexidades:

### 1. **An√°lise Explorat√≥ria de Dados (EDA)**
- Carregar e explorar os datasets de treino e teste
- Entender a distribui√ß√£o das vari√°veis
- Identificar correla√ß√µes entre features
- Visualizar padr√µes nos dados

### 2. **Modelagem Preditiva de Regress√£o**
- Criar modelos para prever a **qualidade do vinho**
- Comparar m√∫ltiplos algoritmos de regress√£o
- Avaliar performance usando m√©tricas adequadas

### 3. **An√°lise de Clustering**
- Identificar grupos naturais nos dados de vinhos
- Aplicar algoritmos de clustering n√£o-supervisionado
- Determinar o n√∫mero √≥timo de clusters
- Visualizar os clusters em espa√ßo reduzido

### 4. **Simula√ß√£o de Dados Faltantes**
- Criar uma vers√£o do dataset de teste com valores faltantes
- Simular um cen√°rio realista de dados incompletos

### 5. **Imputa√ß√£o de Valores Faltantes**
- Desenvolver um sistema de imputa√ß√£o baseado em Machine Learning
- Prever valores faltantes usando modelos treinados
- Validar a qualidade da imputa√ß√£o comparando com dados originais

---

## üìä Dados Dispon√≠veis

### Dataset de Treino (`train.csv`)
- **Amostras**: ~15.000 vinhos
- **Features**: 11 caracter√≠sticas f√≠sico-qu√≠micas
- **Target**: Qualidade do vinho (quality)

### Dataset de Teste (`test.csv`)
- **Amostras**: Conjunto para avalia√ß√£o
- **Features**: Mesmas 11 caracter√≠sticas do treino
- **Target**: N√£o dispon√≠vel (para ser previsto)

### Features Dispon√≠veis:
1. `id` - Identificador √∫nico
2. `fixed acidity` - Acidez fixa
3. `volatile acidity` - Acidez vol√°til
4. `citric acid` - √Åcido c√≠trico
5. `residual sugar` - A√ß√∫car residual
6. `chlorides` - Cloretos
7. `free sulfur dioxide` - Di√≥xido de enxofre livre
8. `total sulfur dioxide` - Di√≥xido de enxofre total
9. `density` - Densidade
10. `pH` - pH
11. `sulphates` - Sulfatos
12. `alcohol` - Teor alco√≥lico
13. `quality` - **Qualidade do vinho** (vari√°vel alvo, apenas no treino)

---

## üéì Etapa 1: An√°lise Explorat√≥ria de Dados

### Objetivos:
- [ ] Carregar os datasets de treino e teste
- [ ] Exibir informa√ß√µes b√°sicas (shape, tipos de dados, valores nulos)
- [ ] Calcular estat√≠sticas descritivas
- [ ] Visualizar a distribui√ß√£o da vari√°vel alvo (`quality`)
- [ ] Criar matriz de correla√ß√£o
- [ ] Visualizar distribui√ß√£o de todas as features num√©ricas

### Pontos de Aten√ß√£o:
- Existem valores nulos nos dados originais?
- Como √© a distribui√ß√£o da qualidade dos vinhos?
- Quais features t√™m maior correla√ß√£o com a qualidade?
- H√° outliers significativos nos dados?

### Visualiza√ß√µes Esperadas:
1. Gr√°fico de barras da distribui√ß√£o de qualidade
2. Histograma da qualidade
3. Matriz de correla√ß√£o (heatmap)
4. Histogramas de todas as features num√©ricas

---

## ü§ñ Etapa 2: Modelagem Preditiva de Regress√£o

### Objetivos:
- [ ] Preparar dados para modelagem (separar X e y)
- [ ] Dividir dados em treino e valida√ß√£o (80/20)
- [ ] Normalizar os dados usando StandardScaler
- [ ] Treinar pelo menos 3 modelos diferentes de regress√£o
- [ ] Avaliar modelos usando m√∫ltiplas m√©tricas

### Modelos Sugeridos:
1. **Regress√£o Linear** - Baseline simples
2. **Random Forest Regressor** - Modelo ensemble baseado em √°rvores
3. **Gradient Boosting Regressor** - Modelo de boosting

### M√©tricas de Avalia√ß√£o:
- **RMSE** (Root Mean Squared Error) - Para treino e valida√ß√£o
- **R¬≤** (R-squared) - Coeficiente de determina√ß√£o
- **MAE** (Mean Absolute Error) - Erro absoluto m√©dio

### Desafio Extra:
- Crie visualiza√ß√µes comparando a performance dos modelos
- Identifique qual modelo tem melhor generaliza√ß√£o (menor overfitting)
- Gr√°ficos de compara√ß√£o side-by-side de RMSE e R¬≤

### Crit√©rios de Sucesso:
- RMSE de valida√ß√£o < 0.65
- R¬≤ de valida√ß√£o > 0.35
- Diferen√ßa entre RMSE treino/valida√ß√£o < 0.15 (evitar overfitting)

---

## üé® Etapa 3: An√°lise de Clustering

### Objetivos:
- [ ] Aplicar m√©todo do cotovelo para determinar k √≥timo
- [ ] Treinar modelo K-Means com k escolhido
- [ ] Analisar distribui√ß√£o de vinhos por cluster
- [ ] Calcular qualidade m√©dia por cluster
- [ ] Visualizar clusters usando PCA (2 componentes)

### M√©todo do Cotovelo:
- Testar valores de k de 2 a 10
- Calcular in√©rcia para cada k
- Plotar curva e identificar "cotovelo"

### An√°lise Esperada:
- Qual √© o n√∫mero √≥timo de clusters?
- Os clusters representam diferentes n√≠veis de qualidade?
- Quantos vinhos h√° em cada cluster?
- Qual cluster cont√©m vinhos de maior qualidade m√©dia?

### Visualiza√ß√£o PCA:
- Reduzir dimensionalidade para 2 componentes principais
- Plotar scatter plot colorido por cluster
- Mostrar vari√¢ncia explicada por cada componente

### Crit√©rios de Sucesso:
- Identificar k √≥timo (provavelmente entre 3-5)
- Clusters bem separados na visualiza√ß√£o PCA
- Vari√¢ncia explicada pelos 2 primeiros componentes > 40%

---

## üé≤ Etapa 4: Simula√ß√£o de Dados Faltantes

### Objetivos:
- [ ] Criar c√≥pia do dataset de teste original
- [ ] Remover valores aleatoriamente de forma controlada
- [ ] Aplicar percentual uniforme de missing values (~20%)
- [ ] Salvar dataset modificado
- [ ] Documentar estat√≠sticas dos valores faltantes

### Especifica√ß√µes:
- **Percentual de valores faltantes**: 20% por coluna
- **Seed para reprodutibilidade**: 42
- **Colunas afetadas**: Todas exceto `id`
- **Distribui√ß√£o**: Aleat√≥ria e uniforme

### Output Esperado:
- Arquivo `test_with_missing_features.csv`
- Relat√≥rio mostrando:
  - N√∫mero total de valores faltantes
  - Valores faltantes por coluna
  - Percentual de missing values por coluna

### Crit√©rios de Sucesso:
- Aproximadamente 20% de valores faltantes por feature
- Distribui√ß√£o aleat√≥ria (n√£o concentrada em poucas linhas)
- ID preservado em todas as linhas

---

## üîÆ Etapa 5: Imputa√ß√£o de Valores Faltantes

Esta √© a **etapa mais desafiadora** do projeto!

### Objetivos:
- [ ] Criar fun√ß√£o para treinar modelo de predi√ß√£o por feature
- [ ] Treinar um modelo espec√≠fico para cada feature com valores faltantes
- [ ] Implementar imputa√ß√£o iterativa
- [ ] Aplicar imputa√ß√£o ao dataset de teste
- [ ] Validar qualidade da imputa√ß√£o

### Abordagem Recomendada:

#### 1. Treinamento de Modelos por Feature
Para cada feature com valores faltantes:
- Usar feature como **target**
- Usar todas as outras features como **preditoras**
- Treinar modelo Random Forest
- Armazenar modelo + scaler + features usadas

#### 2. Imputa√ß√£o Iterativa
- **Itera√ß√£o m√°xima**: 5 itera√ß√µes
- Para cada itera√ß√£o:
  - Identificar valores faltantes
  - Prever usando modelos treinados
  - Preencher valores temporariamente com m√©dia se necess√°rio
  - Imputar valores previstos
- Parar quando n√£o houver mais valores faltantes

#### 3. Fun√ß√£o `treinar_modelo_feature()`
```python
def treinar_modelo_feature(feature_name, train_data):
    """
    Treina um modelo para prever uma feature espec√≠fica
    """
    # Separar features preditoras (todas exceto id, quality, e a feature alvo)
    # Normalizar dados com StandardScaler
    # Treinar RandomForestRegressor
    # Retornar modelo, scaler e lista de features
    pass
```

#### 4. Fun√ß√£o `imputar_valores_faltantes()`
```python
def imputar_valores_faltantes(df_com_missing, modelos_dict, max_iterations=5):
    """
    Imputa valores faltantes iterativamente
    """
    # Para cada itera√ß√£o at√© max_iterations:
    #   Para cada feature com missing values:
    #     Identificar linhas com valores faltantes
    #     Preparar dados para predi√ß√£o
    #     Preencher temporariamente valores faltantes nas features preditoras
    #     Normalizar e fazer predi√ß√£o
    #     Imputar valores previstos
    # Retornar dataframe completo
    pass
```

### Valida√ß√£o:
- [ ] Comparar distribui√ß√µes: original vs imputado
- [ ] Calcular diferen√ßa de m√©dia e desvio padr√£o
- [ ] Criar visualiza√ß√µes comparativas (histogramas + boxplots)
- [ ] Salvar dataset imputado

### Visualiza√ß√µes Esperadas:
1. **Histograma Original** - Distribui√ß√£o dos valores originais
2. **Histograma Imputado** - Distribui√ß√£o ap√≥s imputa√ß√£o
3. **Boxplot Comparativo** - Compara√ß√£o lado a lado

### Crit√©rios de Sucesso:
- **Zero valores faltantes** ap√≥s imputa√ß√£o
- Diferen√ßa de **m√©dia < 5%** entre original e imputado
- Diferen√ßa de **std < 10%** entre original e imputado
- Distribui√ß√µes visualmente similares

---

## üìà M√©tricas de Avalia√ß√£o Final

### Pontua√ß√£o por Etapa:

| Etapa | Peso | Crit√©rios |
|-------|------|-----------|
| **EDA** | 15% | Completude das an√°lises e visualiza√ß√µes |
| **Modelagem** | 25% | Performance dos modelos (RMSE, R¬≤) |
| **Clustering** | 20% | Identifica√ß√£o de k √≥timo e an√°lise dos clusters |
| **Simula√ß√£o** | 10% | Correta gera√ß√£o de valores faltantes |
| **Imputa√ß√£o** | 30% | Qualidade da imputa√ß√£o e preserva√ß√£o de distribui√ß√µes |

### Pontua√ß√£o Extra:
- **+5%**: C√≥digo bem documentado com coment√°rios claros
- **+5%**: Visualiza√ß√µes criativas e informativas al√©m das solicitadas
- **+5%**: An√°lises adicionais ou insights interessantes
- **+5%**: Implementa√ß√£o de t√©cnicas avan√ßadas (ex: hyperparameter tuning)

---

## üõ†Ô∏è Ferramentas e Bibliotecas

### Obrigat√≥rias:
```python
# Manipula√ß√£o de dados
import pandas as pd
import numpy as np

# Visualiza√ß√£o
import matplotlib.pyplot as plt
import seaborn as sns

# Machine Learning
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.cluster import KMeans
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
```

### Opcionais (para explora√ß√£o avan√ßada):
- XGBoost, LightGBM, CatBoost (modelos de boosting avan√ßados)
- Optuna ou GridSearchCV (hyperparameter tuning)
- UMAP (alternativa ao PCA para visualiza√ß√£o)
- Plotly (visualiza√ß√µes interativas)

---

## üìù Estrutura Sugerida do Notebook

```
1. T√≠tulo e Introdu√ß√£o
2. Importa√ß√£o de Bibliotecas
3. Se√ß√£o 1: Carregamento e Prepara√ß√£o de Dados
   - Carregar dados originais
   - Criar dataset com valores faltantes
4. Se√ß√£o 2: An√°lise Explorat√≥ria
   - Estat√≠sticas descritivas
   - Visualiza√ß√µes de distribui√ß√£o
   - Matriz de correla√ß√£o
5. Se√ß√£o 3: Modelagem Preditiva
   - Prepara√ß√£o dos dados
   - Treinamento de modelos
   - Compara√ß√£o de performance
6. Se√ß√£o 4: An√°lise de Clustering
   - M√©todo do cotovelo
   - K-Means
   - Visualiza√ß√£o PCA
7. Se√ß√£o 5: Imputa√ß√£o de Valores Faltantes
   - Fun√ß√µes de treinamento
   - Imputa√ß√£o iterativa
   - Valida√ß√£o e compara√ß√£o
8. Conclus√µes e Insights
```

---

## üèÜ Desafios B√¥nus

### Desafio B√¥nus 1: Ensemble de Imputa√ß√£o
- Treinar m√∫ltiplos modelos (RF, GB, XGB) para cada feature
- Usar m√©dia/mediana das predi√ß√µes para imputa√ß√£o final
- Comparar com abordagem de modelo √∫nico

### Desafio B√¥nus 2: An√°lise de Feature Importance
- Para o melhor modelo de regress√£o, extrair feature importance
- Visualizar top 10 features mais importantes
- Retreinar modelo apenas com top features

### Desafio B√¥nus 3: Predi√ß√£o Final
- Usar melhor modelo treinado na Etapa 2
- Prever qualidade do vinho no dataset de teste (ap√≥s imputa√ß√£o)
- Criar arquivo de submission (`predictions.csv`)

### Desafio B√¥nus 4: An√°lise de Outliers
- Identificar outliers usando IQR ou Z-score
- Visualizar outliers em boxplots
- Comparar performance dos modelos com/sem outliers

### Desafio B√¥nus 5: Valida√ß√£o Cruzada
- Implementar K-Fold Cross-Validation (k=5)
- Calcular m√©dia e desvio padr√£o das m√©tricas
- Comparar estabilidade entre modelos

---

## üìö Recursos de Apoio

### Documenta√ß√£o Oficial:
- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Matplotlib Gallery](https://matplotlib.org/stable/gallery/index.html)
- [Seaborn Tutorial](https://seaborn.pydata.org/tutorial.html)

### Conceitos Importantes:
- **Regress√£o**: Predi√ß√£o de valores cont√≠nuos
- **Clustering**: Agrupamento n√£o-supervisionado
- **Imputa√ß√£o**: Preenchimento de valores faltantes
- **Normaliza√ß√£o**: Padroniza√ß√£o de escalas
- **Overfitting**: Quando modelo memoriza ao inv√©s de generalizar
- **PCA**: Redu√ß√£o de dimensionalidade preservando vari√¢ncia

---

## üéØ Crit√©rios de Entrega

### Arquivo Principal:
- **Nome**: `solution.ipynb`
- **Formato**: Jupyter Notebook
- **Tamanho**: N√£o h√° limite, mas seja eficiente

### Arquivos Gerados:
1. `test_with_missing_features.csv` - Dataset com valores faltantes
2. `test_imputed.csv` - Dataset ap√≥s imputa√ß√£o

### Arquivos Opcionais:
3. `predictions.csv` - Predi√ß√µes de qualidade (Desafio B√¥nus 3)
4. `README.md` - Documenta√ß√£o adicional do seu projeto

### Organiza√ß√£o do C√≥digo:
- ‚úÖ C√©lulas bem organizadas e comentadas
- ‚úÖ T√≠tulos e descri√ß√µes em Markdown
- ‚úÖ Outputs de todas as c√©lulas vis√≠veis
- ‚úÖ C√≥digo execut√°vel do in√≠cio ao fim
- ‚úÖ Seed fixado para reprodutibilidade

---

## üí° Dicas para Sucesso

### Gerais:
1. **Comece pela EDA**: Entenda seus dados antes de modelar
2. **Documente tudo**: Explique suas escolhas e descobertas
3. **Visualize bastante**: Um gr√°fico vale mais que mil n√∫meros
4. **Valide sempre**: Compare resultados com expectativas

### Espec√≠ficas de Imputa√ß√£o:
1. Use `random_state=42` para reprodutibilidade
2. Normalize dados antes de treinar modelos
3. Imputa√ß√£o iterativa √© melhor que single-pass
4. Valide que distribui√ß√µes se preservam ap√≥s imputa√ß√£o

### Otimiza√ß√£o:
1. Use `n_jobs=-1` em modelos para paralelizar
2. Comece com poucos estimadores, aumente depois
3. Cache intermedi√°rios para evitar reprocessamento
4. Monitore tempo de execu√ß√£o das c√©lulas

---

## ‚ùì FAQ - Perguntas Frequentes

**Q: Posso usar modelos diferentes dos sugeridos?**  
R: Sim! Sinta-se livre para experimentar. Os modelos sugeridos s√£o apenas um ponto de partida.

**Q: Preciso fazer todos os desafios b√¥nus?**  
R: N√£o, s√£o opcionais. Fa√ßa se quiser explorar mais ou melhorar sua pontua√ß√£o.

**Q: Como sei se minha imputa√ß√£o est√° boa?**  
R: Compare as distribui√ß√µes visualmente e numericamente. Diferen√ßas < 5% na m√©dia s√£o excelentes.

**Q: Posso usar t√©cnicas de deep learning?**  
R: Sim, mas n√£o √© necess√°rio. M√©todos tradicionais j√° resolvem bem este problema.

**Q: Quanto tempo devo levar para completar?**  
R: Estimativa: 4-6 horas para todas as etapas obrigat√≥rias. B√¥nus podem adicionar 2-4 horas.

**Q: Posso trabalhar em equipe?**  
R: Depende das regras do seu instrutor. Mas aprender colaborando √© sempre bom!

---

## üöÄ Come√ßando

1. Clone/baixe os arquivos do desafio
2. Configure seu ambiente Python com as bibliotecas necess√°rias
3. Abra o Jupyter Notebook
4. Siga as etapas na ordem sugerida
5. Documente suas descobertas e insights
6. Divirta-se explorando os dados! üéâ

---

## üìä Checklist Final

Antes de submeter, verifique:

- [ ] Todas as 5 etapas foram completadas
- [ ] Todas as c√©lulas executam sem erros
- [ ] Visualiza√ß√µes est√£o renderizadas
- [ ] C√≥digo est√° comentado e organizado
- [ ] Arquivos CSV foram gerados corretamente
- [ ] M√©tricas de valida√ß√£o atendem aos crit√©rios m√≠nimos
- [ ] Notebook conta uma "hist√≥ria" clara dos dados

---

## üéì Aprendizados Esperados

Ao completar este desafio, voc√™ ter√° praticado:

‚úÖ An√°lise explorat√≥ria de dados completa  
‚úÖ Visualiza√ß√£o de dados com matplotlib e seaborn  
‚úÖ Modelagem preditiva com m√∫ltiplos algoritmos  
‚úÖ Avalia√ß√£o e compara√ß√£o de modelos  
‚úÖ Clustering n√£o-supervisionado  
‚úÖ Redu√ß√£o de dimensionalidade com PCA  
‚úÖ Imputa√ß√£o inteligente de dados faltantes  
‚úÖ Valida√ß√£o de resultados e qualidade de dados  
‚úÖ Boas pr√°ticas de organiza√ß√£o de c√≥digo  
‚úÖ Pensamento cr√≠tico sobre dados e resultados  

---

## üèÖ Boa Sorte!

Este √© um desafio completo e realista de Data Science. N√£o se preocupe se n√£o conseguir tudo de primeira - o importante √© aprender no processo!

**Lembre-se**: O objetivo n√£o √© apenas completar, mas **entender** cada etapa e ser capaz de explicar suas escolhas.

---

**Vers√£o**: 1.0  
**Autor do Desafio**: Competi√ß√£o Neuron UFLA  
**Data**: 2025  
**Licen√ßa**: Educacional

---

*"In God we trust, all others must bring data." - W. Edwards Deming*
